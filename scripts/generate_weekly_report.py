#!/usr/bin/env python3
"""
Generate Weekly Performance Report Script

This script generates weekly performance reports by filtering data from the main 
model performance analysis. It automatically generates reports for both the 
specified "current" week and the "previous" week.

Usage:
    python scripts/generate_weekly_report.py --week-start 2026-01-05
"""

import os
import sys
import argparse
import html
import shutil
import pandas as pd
import numpy as np
import requests
import base64
import pytz
from io import StringIO
from datetime import datetime, timedelta, timezone

# Add parent directory to path to import from analyze_model_performance
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, parent_dir)

# Import required functions from analyze_model_performance
from analyze_model_performance import (
    fetch_graded_results_from_github,
    collect_spread_performance_by_edge,
    collect_spread_performance_by_point_spread,
    collect_over_under_performance_by_edge,
    RESULT_WIN_COLOR,
    RESULT_LOSS_COLOR,
    RESULT_FONT_WEIGHT
)

# Output directory
WEEKLY_DIR = os.path.join(parent_dir, "docs", "weekly")
CURRENT_WEEK_HTML = os.path.join(WEEKLY_DIR, "current_week.html")
CURRENT_WEEK_CSV = os.path.join(WEEKLY_DIR, "current_week.csv")
PREVIOUS_WEEK_HTML = os.path.join(WEEKLY_DIR, "previous_week.html")
PREVIOUS_WEEK_CSV = os.path.join(WEEKLY_DIR, "previous_week.csv")


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description='Generate weekly performance reports'
    )
    parser.add_argument(
        '--week-start',
        type=str,
        required=True,
        help='Current week start date in YYYY-MM-DD format (e.g., 2026-01-05)'
    )
    parser.add_argument(
        '--output',
        type=str,
        choices=['current', 'previous', 'both'],
        default='both',
        help='Output file to generate (default: both)'
    )
    return parser.parse_args()


def parse_date(date_str):
    """Parse date string to datetime object"""
    try:
        return datetime.strptime(date_str, '%Y-%m-%d')
    except ValueError as e:
        print(f"Error: Invalid date format '{date_str}'. Please use YYYY-MM-DD format.")
        sys.exit(1)


def filter_by_week(df, week_start_str):
    """
    Filter dataframe to only include games within the specified week
    """
    week_start = parse_date(week_start_str)
    week_end = week_start + timedelta(days=6)
    
    print(f"Filtering games from {week_start.strftime('%Y-%m-%d')} to {week_end.strftime('%Y-%m-%d')}...")
    
    date_columns = ['date', 'game_date', 'Date', 'GameDate']
    date_col = next((col for col in date_columns if col in df.columns), None)
    
    if date_col is None:
        print("Error: No date column found in the data")
        sys.exit(1)
    
    df_filtered = df.copy()
    # Treat dates as naive to avoid timezone shifting issues
    df_filtered[date_col] = pd.to_datetime(df_filtered[date_col], errors='coerce')
    
    # Create mask using normalized dates (ignoring time)
    temp_date_col = df_filtered[date_col].dt.normalize()
    week_start_ts = pd.Timestamp(week_start).normalize()
    week_end_ts = pd.Timestamp(week_end).normalize()
    
    mask = (temp_date_col >= week_start_ts) & (temp_date_col <= week_end_ts)
    df_week = df_filtered[mask].copy()
    
    # Format the date column back to string for display
    df_week[date_col] = df_week[date_col].dt.strftime('%Y-%m-%d')
    
    print(f"  Found {len(df_week)} games.")
    return df_week


def deduplicate_tier_results(tier_results):
    """Deduplicate games and recalculate records for a list of tiers"""
    for tier in tier_results:
        if 'games' in tier and tier['games']:
            # Unique key: date, matchup, team, and the line
            seen = {}
            deduped = []
            for g in tier['games']:
                key = (g.get('date'), g.get('matchup'), g.get('team'), 
                       g.get('opening_spread') or g.get('opening_total'))
                
                # Keep the one with higher edge
                edge = float(str(g.get('edge', '0')).rstrip('%') or 0)
                if key not in seen or edge > seen[key][0]:
                    seen[key] = (edge, g)
            
            tier['games'] = [val[1] for val in seen.values()]
            
            # Recalculate record
            wins = sum(1 for g in tier['games'] if g.get('result') == 'Win')
            losses = sum(1 for g in tier['games'] if g.get('result') == 'Loss')
            total = wins + losses
            tier['wins'], tier['losses'] = wins, losses
            tier['record'] = f"{wins}-{losses}"
            tier['pct'] = f"{(wins/total*100):.1f}%" if total > 0 else "0.0%"
            
    return tier_results


def generate_game_details_html(games, bet_type='spread'):
    """Generate HTML table for individual game results"""
    if not games: return '<p>No games in this tier.</p>'
    
    mapping = {
        'spread': ('Opening Spread', 'opening_spread', 'closing_spread'),
        'total': ('Opening Total', 'opening_total', 'closing_total'),
        'moneyline': ('Opening ML', 'opening_moneyline', 'closing_moneyline')
    }
    label, op_col, cl_col = mapping.get(bet_type, ('Opening', 'opening', 'closing'))
    
    headers = ['Date', 'Matchup', 'Team', label, 'Edge', 'Closing', 'Result']
    html_str = '<table class="game-details-table"><thead><tr>'
    for h in headers: html_str += f'<th>{h}</th>'
    html_str += '</tr></thead><tbody>'
    
    for g in games:
        res = g.get('result', 'N/A')
        color = RESULT_WIN_COLOR if res == 'Win' else RESULT_LOSS_COLOR
        html_str += f"""<tr>
            <td>{html.escape(str(g.get('date', 'N/A')))}</td>
            <td>{html.escape(str(g.get('matchup', 'N/A')))}</td>
            <td>{html.escape(str(g.get('team', 'N/A')))}</td>
            <td>{html.escape(str(g.get(op_col, 'N/A')))}</td>
            <td>{html.escape(str(g.get('edge', 'N/A')))}</td>
            <td>{html.escape(str(g.get(cl_col, 'N/A')))}</td>
            <td style="color: {color}; font-weight: {RESULT_FONT_WEIGHT};">{res}</td>
        </tr>"""
    return html_str + '</tbody></table>'


def count_games_in_section(data):
    """Helper to count games across multiple tiers/subsections"""
    if isinstance(data, list):
        return sum(len(t.get('games', [])) for t in data)
    if isinstance(data, dict):
        return sum(count_games_in_section(v) for v in data.values())
    return 0


def generate_weekly_html(analysis_data, week_start_str, week_end_str, timestamp, game_count, report_type='current'):
    """Build the full HTML report string"""
    # [Styling and boilerplate omitted for brevity, keeping same as original template]
    # (The implementation here would use the logic from your provided script to render the tables)
    # ... (Refer to your original file for the full HTML template logic)
    pass # In actual code, include the full generate_weekly_html logic here


def process_week(df, week_start_str, output_type):
    """Main workflow for a single week's report generation"""
    week_end = parse_date(week_start_str) + timedelta(days=6)
    week_end_str = week_end.strftime('%Y-%m-%d')
    
    html_path = CURRENT_WEEK_HTML if output_type == 'current' else PREVIOUS_WEEK_HTML
    csv_path = CURRENT_WEEK_CSV if output_type == 'current' else PREVIOUS_WEEK_CSV
    
    print(f"\n--- Processing {output_type.upper()} Week: {week_start_str} to {week_end_str} ---")
    
    df_week = filter_by_week(df, week_start_str)
    os.makedirs(WEEKLY_DIR, exist_ok=True)
    df_week.to_csv(csv_path, index=False)
    
    # Run analysis using shared functions from analyze_model_performance
    analysis = {
        'spread_by_edge_all': deduplicate_tier_results(collect_spread_performance_by_edge(df_week, False)),
        'spread_by_edge_consensus': deduplicate_tier_results(collect_spread_performance_by_edge(df_week, True)),
        'spread_by_point_spread': {
            'favorites': deduplicate_tier_results(collect_spread_performance_by_point_spread(df_week)['favorites']),
            'underdogs': deduplicate_tier_results(collect_spread_performance_by_point_spread(df_week)['underdogs'])
        },
        'ou_by_edge_all': {
            'overs': deduplicate_tier_results(collect_over_under_performance_by_edge(df_week, False)['overs']),
            'unders': deduplicate_tier_results(collect_over_under_performance_by_edge(df_week, False)['unders'])
        },
        'ou_by_edge_consensus': {
            'overs': deduplicate_tier_results(collect_over_under_performance_by_edge(df_week, True)['overs']),
            'unders': deduplicate_tier_results(collect_over_under_performance_by_edge(df_week, True)['unders'])
        }
    }
    
    timestamp = datetime.now(timezone.utc).strftime("%Y-%m-%d %H:%M:%S UTC")
    # Using the existing HTML generation logic
    from scripts.generate_weekly_report import generate_weekly_html as gen_html
    html_content = gen_html(analysis, week_start_str, week_end_str, timestamp, len(df_week), output_type)
    
    with open(html_path, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ“ {output_type.capitalize()} report saved: {html_path}")


def main():
    args = parse_arguments()
    df = fetch_graded_results_from_github()
    
    if df is None:
        print("Error: Could not load data.")
        sys.exit(1)

    # Current Week
    if args.output in ['current', 'both']:
        process_week(df, args.week_start, 'current')
    
    # Previous Week (Automatically calculate 7 days prior)
    if args.output in ['previous', 'both']:
        prev_start = (parse_date(args.week_start) - timedelta(days=7)).strftime('%Y-%m-%d')
        process_week(df, prev_start, 'previous')


if __name__ == "__main__":
    main()
